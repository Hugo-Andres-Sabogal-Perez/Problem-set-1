#####
# My first Web Scraping
####
require(pacman)
p_load(tidyverse, # contiene las librer?as ggplot, dplyr...
rvest) # web-scraping
require(pacman)
install.packages("pacman")
require(pacman)
p_load(tidyverse, # contiene las librer?as ggplot, dplyr...
rvest) # web-scraping
my_url = "https://quotes.toscrape.com/"
my_html = read_html(my_url) #
View(my_html)
xml_child(my_html, 1)
xml_child(my_html, 2)
browseURL(my_url)
View(my_html)
div<- my_html %>% html_elements("div") %>%
html_elements("a") %>%
html_text2()
div[1]
quote<- my_html %>%
html_elements(".quote")
quote[1]
View(my_html)
xml_child(my_html, 1)
rm(list = ls())
rm(list = ls())
require(pacman)
p_load(tidyverse, # contiene las librer?as ggplot, dplyr...
rvest) # web-scraping
# primeros pasos con rvest
# rvest tiene varias funciones que pueden ser muy ?tiles.
# read_read_html
my_url = "https://quotes.toscrape.com/"
my_html = read_html(my_url) ## leer el html de la p?gina
browseURL(my_url)
div<- my_html %>% html_elements("div")
View(div)
div<- my_html %>% html_elements("div") %>%
html_elements("a")
View(div)
div[[1]]
div<- my_html %>% html_elements("div") %>%
html_elements("a") %>%
html_text2()
div[1]
print(div)
quote<- my_html %>%
html_elements(".quote")
View(quote)
quote[[1]]
tags <- my_html %>%
html_elements(".tag")%>%
html_text2()
print(tags)
div[1]
quote<- my_html %>%
html_elements(".quote")
quote[1]
tags <- my_html %>%
html_elements(".tag")%>%
html_text2()
tags[1]
tags <- my_html %>%
html_elements(".tag")%>%
html_text2()
class(tags)
tyoeof(tags)
typeof(tags)
print(tags)
a<-c("xd", "xd2")
a<-c("xd", 3)
rm(list = ls())
#####
# My first Web Scraping
####
rm(list = ls())
require(pacman)
p_load(tidyverse, # contiene las librer?as ggplot, dplyr...
rvest) # web-scraping
# primeros pasos con rvest
# rvest tiene varias funciones que pueden ser muy ?tiles.
# read_read_html
my_url = "https://quotes.toscrape.com/"
# request el HTML de la p?gina a R.
my_html = read_html(my_url) ## leer el html de la p?gina
##open the page
browseURL(my_url)
## obtengamos el titulo de la p?gina usando funciones simples de
## rvest.
div<- my_html %>% html_elements("div") %>%
html_elements("a") %>%
html_text2()
div[1]
quote<- my_html %>%
html_elements(".quote")
quote[1]
tags <- my_html %>%
html_elements(".tag")%>%
html_text2()
tags[1]
tags <- my_html %>%
html_elements(".tag")%>%
html_text2()
print(tags)
### obtengamos los linnks de cada autor
links<- my_html %>%
html_elements("a")%>%
html_attr("href")
links[2]
## pero obtenemos otros links que no deseamos
links<- my_html %>%
html_elements(".quote") %>%
html_element("a")%>%  #note element no elements
html_attr("href")
links[1]
print(links)
rm(list = ls())
require(pacman)
p_load(tidyverse, # contiene las librer?as ggplot, dplyr...
rvest) # web-scraping
my_link = "https://ignaciomsarmiento.github.io/GEIH2018_sample/"
div<- my_html %>% html_elements("div") %>%
html_elements("col-md-3") %>%
html_text2()
rm(list = ls())
require(pacman)
p_load(tidyverse, # contiene las librer?as ggplot, dplyr...
rvest) # web-scraping
my_link = "https://ignaciomsarmiento.github.io/GEIH2018_sample/"
my_html = read_html(my_link)
div<- my_html %>% html_elements("div")
View(div)
div<- my_html %>% html_elements("div") %>%
html_elements("col-md-3") %>%
View(div)
div<- my_html %>% html_elements("div") %>%
html_elements("col-md-3") %>%
html_text2()
div<- my_html %>% html_elements("div") %>%
html_elements(".col-md-3") %>%
html_text2()
div<- my_html %>% html_elements("div") %>%
html_elements(".col-md-3")
View(div)
View(div)
div<- my_html %>% html_elements("div") %>%
html_elements("col-md-3")
div<- my_html %>% html_elements("div") %>%
html_elements(".col-md-3")
View(div)
div[[1]]
div<- my_html %>%
html_elements(".col-md-3")
div<- my_html %>%  html_elements(".col-md-3")
View(div)
div<- my_html %>%  html_elements(".col-md-9")
View(div)
xml_child(div[[1]], 1)
div<- my_html %>%  html_elements(".col-md-9")  %>%
html_elements("a")
View(div)
div<- my_html %>%  html_elements(".col-md-9")  %>%
html_elements("ul")
View(div)
xml_child(div[[1]], 1)}
xml_child(div[[1]], 1)
div<- my_html %>%  html_elements(".col-md-9")  %>%
html_elements("ul") %>%  html_elements("a")
View(div)
rm(list = ls())
require(pacman)
require(tidyverse)
require(rvest)
# 1. Importar la base de datos:
html1 = read_html('https://ignaciomsarmiento.github.io/GEIH2018_sample/pages/geih_page_1.html')
html2 = read_html('https://ignaciomsarmiento.github.io/GEIH2018_sample/pages/geih_page_2.html')
html3 = read_html('https://ignaciomsarmiento.github.io/GEIH2018_sample/pages/geih_page_3.html')
html4 = read_html('https://ignaciomsarmiento.github.io/GEIH2018_sample/pages/geih_page_4.html')
html5 = read_html('https://ignaciomsarmiento.github.io/GEIH2018_sample/pages/geih_page_5.html')
html6 = read_html('https://ignaciomsarmiento.github.io/GEIH2018_sample/pages/geih_page_6.html')
html7 = read_html('https://ignaciomsarmiento.github.io/GEIH2018_sample/pages/geih_page_7.html')
html8 = read_html('https://ignaciomsarmiento.github.io/GEIH2018_sample/pages/geih_page_8.html')
html9 = read_html('https://ignaciomsarmiento.github.io/GEIH2018_sample/pages/geih_page_9.html')
html10 = read_html('https://ignaciomsarmiento.github.io/GEIH2018_sample/pages/geih_page_10.html')
C1 = html1 %>% html_table()
C2 = html2 %>% html_table()
C3 = html3 %>% html_table()
C4 = html4 %>% html_table()
C5 = html5 %>% html_table()
C6 = html6 %>% html_table()
C7 = html7 %>% html_table()
C8 = html8 %>% html_table()
C9 = html9 %>% html_table()
C10 = html10 %>% html_table()
Df1 = as.data.frame(C1[1])
Df2 = as.data.frame(C2[1])
Df3 = as.data.frame(C3[1])
Df4 = as.data.frame(C4[1])
Df5 = as.data.frame(C5[1])
Df6 = as.data.frame(C6[1])
Df7 = as.data.frame(C7[1])
Df8 = as.data.frame(C8[1])
Df9 = as.data.frame(C9[1])
Df10 = as.data.frame(C10[1])
# Juntar bases de datos:
DF = rbind(Df1, Df2, Df3, Df4, Df5, Df6, Df7, Df8, Df9, Df10)
# Drop variables inecasarias:
rm(html1, html2, html3, html4, html5, html6, html7, html8, html9, html10, C1, C2, C3, C4, C5, C6, C7, C8, C9, C10,
Df1, Df2, Df3, Df4, Df5, Df6, Df7, Df8, Df9, Df10)
# Seleccion de la muetra de interes: edad >= 18 y empleado (dsi).
DF = DF[DF$age >= 18 & DF$dsi != 1,]
DF = DF[,-1]
# 2. Estadisticas descriptivas:
vars = length(colnames(DF))
ED = data.frame('Variable' = colnames(DF), 'Tipo' = rep(NA, vars) , 'Missings' = rep(NA, vars), 'Media' =  rep(NA, vars),
'Desviacion Estandard' = rep(NA, vars))
for(col in colnames(DF)){
df = DF[,colnames(DF) == col]
NAs = sum(is.na(df))
mean = mean(df, na.rm = T)
sd = sqrt(var(df, na.rm = T))
ED[ED$Variable == col, 3] = NAs
ED[ED$Variable == col, 4] = mean
ED[ED$Variable == col, 5] = sd
}
?stargazer()
?stargazer
install.packages("stargazer")
require(pacman)
require(pacman)
rm(list = ls())
require(pacman)
require(tidyverse)
require(rvest)
require(library)
# 1. Importar la base de datos:
html1 = read_html('https://ignaciomsarmiento.github.io/GEIH2018_sample/pages/geih_page_1.html')
html2 = read_html('https://ignaciomsarmiento.github.io/GEIH2018_sample/pages/geih_page_2.html')
html3 = read_html('https://ignaciomsarmiento.github.io/GEIH2018_sample/pages/geih_page_3.html')
html4 = read_html('https://ignaciomsarmiento.github.io/GEIH2018_sample/pages/geih_page_4.html')
html5 = read_html('https://ignaciomsarmiento.github.io/GEIH2018_sample/pages/geih_page_5.html')
html6 = read_html('https://ignaciomsarmiento.github.io/GEIH2018_sample/pages/geih_page_6.html')
html7 = read_html('https://ignaciomsarmiento.github.io/GEIH2018_sample/pages/geih_page_7.html')
html8 = read_html('https://ignaciomsarmiento.github.io/GEIH2018_sample/pages/geih_page_8.html')
html9 = read_html('https://ignaciomsarmiento.github.io/GEIH2018_sample/pages/geih_page_9.html')
html10 = read_html('https://ignaciomsarmiento.github.io/GEIH2018_sample/pages/geih_page_10.html')
C1 = html1 %>% html_table()
C2 = html2 %>% html_table()
C3 = html3 %>% html_table()
C4 = html4 %>% html_table()
C5 = html5 %>% html_table()
C6 = html6 %>% html_table()
C7 = html7 %>% html_table()
C8 = html8 %>% html_table()
C9 = html9 %>% html_table()
C10 = html10 %>% html_table()
Df1 = as.data.frame(C1[1])
Df2 = as.data.frame(C2[1])
Df3 = as.data.frame(C3[1])
Df4 = as.data.frame(C4[1])
Df5 = as.data.frame(C5[1])
Df6 = as.data.frame(C6[1])
Df7 = as.data.frame(C7[1])
Df8 = as.data.frame(C8[1])
Df9 = as.data.frame(C9[1])
Df10 = as.data.frame(C10[1])
# Juntar bases de datos:
DF = rbind(Df1, Df2, Df3, Df4, Df5, Df6, Df7, Df8, Df9, Df10)
# Drop variables inecasarias:
rm(html1, html2, html3, html4, html5, html6, html7, html8, html9, html10, C1, C2, C3, C4, C5, C6, C7, C8, C9, C10,
Df1, Df2, Df3, Df4, Df5, Df6, Df7, Df8, Df9, Df10)
# Seleccion de la muetra de interes: edad >= 18 y empleado (dsi).
DF = DF[DF$age >= 18 & DF$ocu != 1,]
DF = DF[,-1]
# 2. Estadisticas descriptivas:
#salario real o nominal?
base= DF %>% select(age,clase,depto,formal,maxEducLevel,orden,p6426,p7040,sex,sizeFirm,y_ingLab_m_ha)
stargazer(base, type= "text", summary=T, title = "Estadisticas Descriptivas",out = "Views/esta_des.txt")
#limpiar entorno
rm(list = ls())
rm(list = ls())
require(pacman)
require(tidyverse)
require(rvest)
require(stargazer)
require(rio)
require(caret)
require(gridExtra)
require(skimr)
require(boot)
require(tidytable)
DF<-import("Stores/DF.csv")
base= DF %>% select(age,oficio, formal, maxEducLevel, orden, p7040, sex, sizeFirm, y_ingLab_m_ha, hoursWorkUsual)
stargazer(base, type= "text", summary=T, title = "Estadisticas Descriptivas",out = "Views/esta_des.txt")
base$ln_sal = log(base$y_ingLab_m_ha)
vars = length(colnames(base))
missingb = data.frame('Variable' = colnames(base), 'Missings' = rep(NA, vars))
for(col in colnames(base)){
df = base[,colnames(base) == col]
NAs = sum(is.na(df))
missingb[missingb$Variable == col, 2] = NAs
}
# Eliminar la observacion:
base = base[!(is.na(base$maxEducLevel)),]
#creamos un ID
base$id<-rownames(base)
base$Female <- ifelse(base$sex == 0, 1, 0)
modelo3 <- lm(ln_sal~ Female + age + maxEducLevel + formal + oficio + hoursWorkUsual + p7040 + sizeFirm + factor(id) , data=base)
modelo3
modelo2 <- lm(ln_sal~ Female , data=base)
modelo2
stargazer(modelo3, keep="Female", type="text", title = "Resultados Modelo 3", out = "Views/mod3.txt")
ypmod = lm(ln_sal ~ age + maxEducLevel + formal + oficio + hoursWorkUsual + p7040 + sizeFirm + factor(id), data=base)
xpmod = lm(Female ~ age + maxEducLevel + formal + oficio + hoursWorkUsual + p7040 + sizeFirm + factor(id), data=base)
yprima = residuals(ypmod)
xprima = residuals(xpmod)
FWL = data.frame('yprima' = yprima, 'xprima' = xprima)
fwlmod = lm(yprima ~ xprima, data = FWL)
vars = length(colnames(DF))
ED = data.frame('Variable' = colnames(DF), 'Tipo' = rep(NA, vars) , 'Missings' = rep(NA, vars), 'Media' =  rep(NA, vars),
'Desviacion Estandard' = rep(NA, vars))
for(col in colnames(DF)){
df = DF[,colnames(DF) == col]
NAs = sum(is.na(df))
mean = mean(df, na.rm = T)
sd = sqrt(var(df, na.rm = T))
ED[ED$Variable == col, 3] = NAs
ED[ED$Variable == col, 4] = mean
ED[ED$Variable == col, 5] = sd
}
C = ED %>% filter(Desviacion.Estandard == 0) %>% select(Variable) %>% as.vector()
View(ED)
stargazer(fwlmod, type="text", title = "Resultados FWL Simple", out = "Views/mod2.txt")
View(FWL)
View(fwlmod)
View(fwlmod)
yprima[residuals]
ypmod[residuals]
ypmod["residuals"]
modelo3 <- lm(ln_sal~ Female + age + maxEducLevel + formal + oficio + hoursWorkUsual + p7040 + sizeFirm, data=base)
modelo3
stargazer(modelo3, type="text", title = "Resultados Modelo 3", out = "Views/mod3.txt")
ypmod = lm(ln_sal ~ age + maxEducLevel + formal + oficio + hoursWorkUsual + p7040 + sizeFirm, data=base)
xpmod = lm(Female ~ age + maxEducLevel + formal + oficio + hoursWorkUsual + p7040 + sizeFirm, data=base)
FWL = data.frame('yprima' = ypmod["residuals"], 'xprima' = xpmod["residuals"])
fwlmod = lm(yprima ~ xprima, data = FWL)
stargazer(fwlmod, type="text", title = "Resultados FWL Simple", out = "Views/mod2.txt")
View(FWL)
View(FWL)
fwlmod = lm(residuals ~ residuals.1, data = FWL)
stargazer(fwlmod, type="text", title = "Resultados FWL Simple", out = "Views/mod2.txt")
FWL_boots <-function(data,index){
ypmod = lm(ln_sal ~ age + maxEducLevel + formal + oficio + hoursWorkUsual + p7040 + sizeFirm, data, subset=index)
xpmod = lm(Female ~ age + maxEducLevel + formal + oficio + hoursWorkUsual + p7040 + sizeFirm,data, subset=index)
yprima = ypmod["residuals"]
xprima = xpmod["residuals"]
FWL = data.frame('yprima' = yprima, 'xprima' = xprima)
fwlmod = lm(yprima ~ xprima, data = FWL)
coefs = fwlmod$coefficients[1]
return(coefs)
}
wage_gap = boot(data=base, FWL_boots, R=nrow(base))
FWL_boots <-function(data,index){
ypmod = lm(ln_sal ~ age + maxEducLevel + formal + oficio + hoursWorkUsual + p7040 + sizeFirm, data, subset=index)
xpmod = lm(Female ~ age + maxEducLevel + formal + oficio + hoursWorkUsual + p7040 + sizeFirm,data, subset=index)
yprima = ypmod["residuals"]
xprima = xpmod["residuals"]
FWL = data.frame('yprima' = yprima, 'xprima' = xprima)
colnames(FWL)= c("yprima", "xprima")
fwlmod = lm(yprima ~ xprima, data = FWL)
coefs = fwlmod$coefficients[1]
return(coefs)
}
wage_gap = boot(data=base, FWL_boots, R=nrow(base))
wage_gap
# Calculo intervalo de confianza:
boot.ci(boot.out = wage_gap, conf = c(0.95, 0.99), type = 'all')
DF<-importar_datos()
write.csv(x = DF, file = "Stores/DF.csv", row.names = FALSE)
DF<-import("Stores/DF.csv")
rm(list = ls())
#Llamamos las librerías necesarias para la realización del trabajo
require(pacman)
require(tidyverse)
require(rvest)
require(stargazer)
require(rio)
require(caret)
require(gridExtra)
require(skimr)
require(boot)
require(tidytable)
DF<-importar_datos()
rm(list = ls())
#Llamamos las librerías necesarias para la realización del trabajo
require(pacman)
require(tidyverse)
require(rvest)
require(stargazer)
require(rio)
require(caret)
require(gridExtra)
require(skimr)
require(boot)
require(tidytable)
write.csv(x = DF, file = "Stores/DF.csv", row.names = FALSE)
DF<-importar_datos()
rm(list = ls())
require(pacman)
require(tidyverse)
require(rvest)
require(stargazer)
require(rio)
require(caret)
require(gridExtra)
require(skimr)
require(boot)
require(tidytable)
library(grid)
DF<-importar_datos()
?importar_datos
